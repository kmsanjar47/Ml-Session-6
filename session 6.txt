Competition Link : https://www.kaggle.com/competitions/titanic/overview

Steps : Go tot link -> Join Comp -> upload ipynb -> run ipynb -> submit prediction-> upvote -> comment


****Overfitting, Underfitting*****

Overfitting -> Train Score Very High(near 100%) but test score very low compared to train score (Multicolinearity)
Underfitting -> Both of our test and train score very low


Classification: Confusion Matrix, Recall, Precision, Roc Auc curve etc etc
Regression : MAE, MSE, RMSE, R2 score etc etc


Cross Validation : 

	data -> df

	- Hold Out Cross Validation -(Train Test Split) 1 time
	- K-Fold Cross Validation - fold
	- Stratified K Fold Cross Validation -
	- Leave One-Out Cross Validation (LOOCV)


30 % Test && 70% Train (29% no 71% yes)

# Ensemble methods